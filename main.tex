% Created 2025-06-28 Sat 11:11
% Intended LaTeX compiler: pdflatex
\documentclass[10pt]{book}
%% CREATO CON ORG - EMACS
\newcommand{\use}[2][]{\usepackage[#1]{#2}}
% PACCHETTI FONDAMENTLAI
\use[utf8]{inputenc}
\use[T1]{fontenc}
\use{graphicx}
\use{longtable}
\use{wrapfig}
\use{rotating}
\use[normalem]{ulem}
\use{amsmath}
\use{amsthm}
\use{amssymb}
\use{capt-of}
\use[italian]{babel}
\use[babel]{csquotes}
\use[style=numeric, hyperref]{biblatex}
\use{microtype}
\use{lmodern}
\use{subfig} % sottofigure
\use{multicol} % due colonne
\use{lipsum} % lorem ipsum
\use{color} % colori in latex
\use{parskip} % rimuove l'indentazione dei nuovi paragrafi %% Add parbox=false to all new tcolorbox
\use{centernot}
\use[outline]{contour}\contourlength{3pt}
\use{fancyhdr}
\use{layout}
\use[most]{tcolorbox} % Riquadri colorati
\use{ifthen} % IFTHEN
\use{geometry}

% pacchetti matematica
\use{yhmath}
\use{dsfont}
\use{mathrsfs}
\use{cancel} % semplificare
\use{polynom} %divisione tra polinomi
\use{forest} % grafi ad albero
\use{booktabs} % tabelle
\use{commath} %simboli e differenziali
\use{bm} %bold
\use[fulladjust]{marginnote} %to use marginnote for date notes
\use{arrayjobx}%array
\use[intlimits]{empheq} % Riquadri colorati attorno alle equazioni
\use{mathtools}
\use{circuitikz} % Disegnare i circuiti

%%%%%%%%%%%%%


%%%% QUIVER
\newcommand{\duepunti}{\,\mathchar\numexpr"6000+`:\relax\,}
% A TikZ style for curved arrows of a fixed height, due to AndréC.
\tikzset{curve/.style={settings={#1},to path={(\tikztostart)
    .. controls ($(\tikztostart)!\pv{pos}!(\tikztotarget)!\pv{height}!270:(\tikztotarget)$)
    and ($(\tikztostart)!1-\pv{pos}!(\tikztotarget)!\pv{height}!270:(\tikztotarget)$)
    .. (\tikztotarget)\tikztonodes}},
    settings/.code={\tikzset{quiver/.cd,#1}
        \def\pv##1{\pgfkeysvalueof{/tikz/quiver/##1}}},
    quiver/.cd,pos/.initial=0.35,height/.initial=0}

% TikZ arrowhead/tail styles.
\tikzset{tail reversed/.code={\pgfsetarrowsstart{tikzcd to}}}
\tikzset{2tail/.code={\pgfsetarrowsstart{Implies[reversed]}}}
\tikzset{2tail reversed/.code={\pgfsetarrowsstart{Implies}}}
% TikZ arrow styles.
\tikzset{no body/.style={/tikz/dash pattern=on 0 off 1mm}}
%%%%%%%%%%


%% DEFINIZIONI COMANDI MATEMATICI
\let\sin\relax %TOGLIE LA DEFINIZIONE SU "\sin"

% cambia la definizione di empty set
% ---
\let\oldemptyset\emptyset
% ---
% \let\emptyset\varnothing
% ---
% \let\emptyset\relax
% \newcommand{\emptyset}{\text{\textnormal{\O}}}
% ---

\DeclareMathOperator{\bounded}{bd}
\DeclareMathOperator{\sin}{sen}
\DeclareMathOperator{\epi}{Epi}
\DeclareMathOperator{\cl}{cl}
\DeclareMathOperator{\graph}{graph}
\DeclareMathOperator{\arcsec}{arcsec}
\DeclareMathOperator{\arccot}{arccot}
\DeclareMathOperator{\arccsc}{arccsc}
\DeclareMathOperator{\spettro}{Spettro}
\DeclareMathOperator{\nulls}{nullspace}
\DeclareMathOperator{\dom}{dom}
\DeclareMathOperator{\ar}{ar}
\DeclareMathOperator{\const}{Const}
\DeclareMathOperator{\fun}{Fun}
\DeclareMathOperator{\rel}{Rel}
\DeclareMathOperator{\altezza}{ht}
\let\det\relax %TOGLIE LA DEFINIZIONE SU "\det"
\DeclareMathOperator{\det}{det}
\DeclareMathOperator{\End}{End}
\DeclareMathOperator{\gl}{GL}
\DeclareMathOperator{\Id}{Id}
\DeclareMathOperator{\id}{Id}
\DeclareMathOperator{\I}{\mathds{1}}
\DeclareMathOperator{\II}{II}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\tc}{t.c.}
\DeclareMathOperator{\T}{T}
\DeclareMathOperator{\var}{Var}
\DeclareMathOperator{\cov}{Cov}
\DeclareMathOperator{\st}{st}
\DeclareMathOperator{\mon}{Mon}
\newcommand{\card}[1]{\left\vert #1 \right\vert}
\newcommand{\trasposta}[1]{\prescript{\text{T}}{}{#1}}
\newcommand{\1}{\mathds{1}}
\newcommand{\R}{\mathds{R}}
\newcommand{\diesis}{\#}
\newcommand{\bemolle}{\flat}
\newcommand{\nonstandard}[1]{\prescript{*}{}{#1}}
\newcommand{\starR}{\nonstandard{\R}}
\newcommand{\borel}{\mathscr{B}}
\newcommand{\lebesgue}[1]{\mathscr{L}\left(#1\right)}
\newcommand{\media}{\mathds{E}}
\newcommand{\K}{\mathds{K}}
\newcommand{\A}{\mathds{A}}
\newcommand{\Q}{\mathds{Q}}
\newcommand{\N}{\mathds{N}}
\newcommand{\C}{\mathds{C}}
\newcommand{\Z}{\mathds{Z}}
\newcommand{\qo}{\hspace{1em}\text{q.o.}\,}
\renewcommand{\tilde}[1]{\widetilde{#1}}
\renewcommand{\parallel}{\mathrel{/\mkern-5mu/}}
\newcommand{\parti}[2][]{\wp_{#1}(#2)}
\newcommand{\diff}[1]{\operatorname{d}_{#1}}
\let\oldvec\vec
\renewcommand{\vec}[1]{\overrightarrow{\vphantom{i}#1}}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\cat}[1]{\mathbf{#1}}
\newcommand{\dfreccia}[1]{\xrightarrow{\ #1 \ }}
\newcommand{\sfreccia}[1]{\xleftarrow{\ #1 \ }}
\newcommand{\formalsum}[2]{{\sum_{#1}^{#2}}{\vphantom{\sum}}'}
\newcommand{\minim}[2]{\mu_{#1}\, \left(#2\right)}
\newcommand{\concat}{\null^{\frown}} % concatenazione di stringe
\newcommand{\godelcode}[1]{\langle\!\langle #1 \rangle\!\rangle}
\newcommand{\godeldec}[1]{(\!(#1)\!)}
\newcommand{\termcode}[1]{\ulcorner #1\urcorner}
\newcommand{\partialto}{\dashrightarrow}
\newcommand{\restricted}{\upharpoonright}
\newcommand{\embeds}{\precsim}
\newcommand{\surjects}{\twoheadrightarrow}
\newcommand{\equipotenti}{\asymp}
%% \newcommand{\dotplus}{\mathbin{\dot{+}}} %% A quanto pare esiste già
\newcommand{\bigdot}{\mathbin{\boldsymbol{\cdot}}}
\newcommand{\dotexp}[1]{^{.#1}}

%% Definizione di \dotminus

\makeatletter
\newcommand{\dotminus}{\mathbin{\text{\@dotminus}}}

\newcommand{\@dotminus}{%
  \ooalign{\hidewidth\raise1ex\hbox{.}\hidewidth\cr$\m@th-$\cr}%
}
\makeatother

%tramite i prossimi due comandi posso decidere come scrivere i logaritmi naturali in tutti i documenti: ho infatti eliminato qualsiasi differenza tra "ln" e "log": se si vuole qualcosa di diverso bisogna inserire manualmente il tutto
\let\ln\relax
\DeclareMathOperator{\ln}{ln}
\let\log\relax
\DeclareMathOperator{\log}{log}
%%%%%%

%% NUOVI COMANDI
\newcommand{\straniero}[1]{\textit{#1}} %parole straniere
\newcommand{\titolo}[1]{\textsc{#1}} %titoli
\newcommand{\qedd}{\tag*{$\blacksquare$}} %qed per ambienti matemastici
\renewcommand{\qedsymbol}{$\blacksquare$} %modifica colore qed
\newcommand{\ooverline}[1]{\overline{\overline{#1}}}
\newcommand{\circoletto}[1]{\left(#1\right)^{\text{o}}}
%
\newcommand{\qmatrice}[1]{\begin{pmatrix}
#1_{11} & \cdots & #1_{1n}\\
\vdots & \ddots & \vdots \\
#1_{m1} & \cdots & #1_{mn}
\end{pmatrix}}
%
\newcommand{\parentesi}[2]{%
\underset{#1}{\underbrace{#2}}%
}
%
\newcommand{\norma}[1]{% Norma
\left\lVert#1\right\rVert%
}
\newcommand{\scalare}[2]{% Scalare
\left\langle #1, #2\right\rangle
}
%%%%%

%% RESTRIZIONI
\newcommand{\referenze}[2]{
	\phantomsection{}#2\textsuperscript{\textcolor{blue}{\textbf{#1}}}
}

\let\restriction\relax

\def\restriction#1#2{\mathchoice
              {\setbox1\hbox{${\displaystyle #1}_{\scriptstyle #2}$}
              \restrictionaux{#1}{#2}}
              {\setbox1\hbox{${\textstyle #1}_{\scriptstyle #2}$}
              \restrictionaux{#1}{#2}}
              {\setbox1\hbox{${\scriptstyle #1}_{\scriptscriptstyle #2}$}
              \restrictionaux{#1}{#2}}
              {\setbox1\hbox{${\scriptscriptstyle #1}_{\scriptscriptstyle #2}$}
              \restrictionaux{#1}{#2}}}
\def\restrictionaux#1#2{{#1\,\smash{\vrule height .8\ht1 depth .85\dp1}}_{\,#2}}
%%%%%%%%%%%

%% SEZIONE GRAFICA
\use{tikz}
\usetikzlibrary{matrix, patterns, calc, decorations.pathreplacing, hobby, decorations.markings, decorations.pathmorphing, babel}
\use{tikz-3dplot}
\use{mathrsfs} %per geogebra
\use{tikz-cd}
\tikzset
{
  %surface/.style={fill=black!10, shading=ball,fill opacity=0.4},
  plane/.style={black,pattern=north east lines},
  curve/.style={black,line width=0.5mm},
  dritto/.style={decoration={markings,mark=at position 0.5 with {\arrow{Stealth}}}, postaction=decorate},
  rovescio/.style={decoration={markings,mark=at position 0.5 with {\arrow{Stealth[reversed]}}}, postaction=decorate}
}
\use{pgfplots} % stampare le funzioni
	\pgfplotsset{/pgf/number format/use comma,compat=1.15}
	%\pgfplotsset{compat=1.15} %per geogebra
	\usepgfplotslibrary{fillbetween, polar}
%%%%%%

%% CITAZIONI
\use{lineno}

\newcommand{\citazione}[1]{%
  \begin{quotation}
  \begin{linenumbers}
  \modulolinenumbers[5]
  \begingroup
  \setlength{\parindent}{0cm}
  \noindent #1
  \endgroup
  \end{linenumbers}
  \end{quotation}\setcounter{linenumber}{1}
  }
%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% AMS THM

\theoremstyle{definition}% default
\newtheorem{thm}{Teorema}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposizione}
\newtheorem{cor}[thm]{Corollario}
\theoremstyle{plain}
\newtheorem{definizione}[thm]{Definizione}
\theoremstyle{remark}
\newtheorem*{oss}{Osservazione}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\use{hyperref}
\hypersetup{%
	pdfauthor={Davide Peccioli},
	pdfsubject={},
	allcolors=black,
	citecolor=black,
%	colorlinks=true,
	bookmarksopen=true}
\pagestyle{empty}

\renewcommand{\href}[2]{\textcolor{blue}{#2}}
\author{Davide Peccioli}
\date{a.a. 2024-25}
\title{Metodi Matematici per il Machine Learning}
\begin{document}

\maketitle
\tableofcontents

\part{De Rossi}
\chapter{Reti Neurali}
\label{sec:orgb3e2895}

\section{Neurone Artificiale}
\label{sec:orge4cf044}
Un \uline{neurone} è una cellula del corpo umano che può essere schematizzata come segue:
\begin{quote}
A neuron is a cell which consists of the following parts: dendrites, axon,and body-cell. The synapse is the connection between the axon of one neuron and the dendrite of another. The functions of each part is briefly described below:
\begin{itemize}
\item Dendrites are transmission channels that collect information from the axons of other neurons. The signal traveling through an axon reaches its terminal end and produces some chemicals \(x_{i}\) which are liberated in the synaptic gap. These chemicals are acting on the dendrites of the next neuron either in a strong or a weak way. The connection strength is described by the weight system \(w_{i}\)-
\item The body-cell collects all signals from dendrites. Here the dendrites activity adds up into a total potential and if a certain threshold is reached, the neuron fires a signal through the axon. The threshold depends on the sensitivity of the neuron and measures how easy is to get the neuron to fire.
\item The axon is the channel for signal propagation. The signal consists in the movement of ions from the body-cell towards the end of the axon. The signal is transmitted electrochemically to the dendrites of the next neuron.
\end{itemize}
\end{quote}

Matematicamente, quindi, si considera un neurone come una unità che riceve degli input (un vettore \(\bm{x}\)), lo \href{../../../../../org/roam/20250625095723-prodotto_scalare.org}{moltiplica} per un vettore di pesi \(\bm{w} = (w_{0},\dots,w_{n})\), e produce un output processando il prodotto scalare tramite una \uline{\hyperref[sec:org4933a3a]{funzione di attivazione}}:
\begin{equation*}
\begin{tikzcd}[ampersand replacement=\&,cramped]
	{\text{Input: }\bm{x}} \\
	{\bm{x}\cdot\bm{w}} \\
	{\text{Funzione di attivazione}} \\
	{\text{Output: }y}
	\arrow[from=1-1, to=2-1]
	\arrow[from=2-1, to=3-1]
	\arrow[from=3-1, to=4-1]
\end{tikzcd}
\end{equation*}
\subsection{Neurone Sigma-Heaviside}
\label{sec:org8825059}

Il modello più semplice è quello che riceve degli input, li somma dopo averli moltiplicati per dei pesi, e:
\begin{itemize}
\item restituisce \(0\) se la somma così ottenuta non supera un \uline{treshold} \(b\);
\item restituisce \(1\) se la somma così ottenuta è maggiore o uguale a \(b\).
\end{itemize}

Questo viene schematizzato in questo modo:
\begin{equation*}
\begin{tikzcd}[ampersand replacement=\&,cramped]
	{-1} \\
	{x_1} \\
	{x_2} \&\& {\boxed{\Sigma, H}} \&\& y \\
	\vdots \\
	{x_n}
	\arrow["b"{description}, from=1-1, to=3-3]
	\arrow["{w_1}"{description}, from=2-1, to=3-3]
	\arrow["{w_2}"{description}, from=3-1, to=3-3]
	\arrow[from=3-3, to=3-5]
	\arrow["{w_n}"{description}, from=5-1, to=3-3]
\end{tikzcd}
\end{equation*}
e l'output \(y\) è dato da\footnote{La funzione \(H:\R\to \R\) è la \href{../../../../../org/roam/20250624161413-funzione_di_heaviside.org}{Funzione di Heaviside}:
\begin{equation*}
H(x) = \begin{cases}
1 & x\ge 0\\
0 & x<0
\end{cases}
\end{equation*}}
\begin{equation*}
y=H\left(\sum_{i=0}^{n} x_{i}\,w_{i}\right)
\end{equation*}
dove per convenzione si è posto \(w_{0}=b\) e \(x_{0}=-1\).

La convenzione è per semplicità di notazione, infatti
\begin{equation*}
H\left(\sum_{i=0}^{n} x_{i}\,w_{i}\right)=\begin{cases}
1 & \sum_{i=1}^{n} x_{i}\, w_{i}\ge b\\
0 & \sum_{i=1}^{n} x_{i}\, w_{i}< b
\end{cases}
\end{equation*}
\subsection{Regressione Lineare}
\label{sec:org7a9d177}

Un altro esempio di neurone è quello che approssima\footnote{Approssima in senso \(L^{2}\) (ovvero minimizza la \href{../../../../../org/roam/20250624162220-spazi_lp.org}{norma \(L^{2}\)} della differenza).} una \href{../../../../../org/roam/20250103103252-funzione_continua.org}{funzione continua}
\begin{equation*}
f: K\to \R
\end{equation*}
con \(K \subseteq \R^{n}\) \href{../../../../../org/roam/20250103163701-spazio_topologico_compatto.org}{compatto}.

L'input del neurone sarà una \href{../../../../../org/roam/20250206170922-sequenze_e_stringhe.org}{\(n\)-upla} \(X=(x_{1},\dots,x_{n}) \in K\), mentre l'output sarà la funzione lineare
\begin{equation*}
L(X) = b+\sum_{i=1}^{n} a_{i}\,x_{i}
\end{equation*}

Per semplicità si considera l'approssimazione vicino allo zero, e si suppone che
\begin{equation*}
L(0)=f(0)=0
\end{equation*}
(a meno di traslazione verticale per \(f(0)\)).

Si vuole quindi minimizzare
\begin{equation*}
C(a_{1},\dots,a_{n}) = \frac{1}{2}\norma{f-L}_{L^{2}} = \frac{1}{2}\int_{K} \left(\sum_{i=1}^{n} a_{i}x_{i} - f(X)\right)^{2}\dif x_{1}\cdots\dif x_{n}
\end{equation*}
calcolandone il \href{../../../../../org/roam/20250624171244-gradiente_di_una_funzione.org}{gradiente}
\begin{align*}
\dpd{C}{a_{k}} &= \int_{K} x_{k} \left(\sum_{i=1}^{n} a_{i}x_{i} - f(X)\right)\dif x_{1}\cdots\dif x_{n}\\
&= \sum_{i=1}^{n} a_{i} \int_{K} x_{i} x_{k}\dif x_{1}\cdots\dif x_{n} - \int_{K} x_{k} f(X)\dif x_{1}\cdots\dif x_{n}
\end{align*}
e dunque, posti
\begin{equation*}
\rho_{ij} \coloneqq \int_{K} x_{i}x_{j}\dif x_{1}\cdots\dif x_{n},\qquad m_{k} \coloneqq \int_{K} x_{k}f(X)\dif x_{1}\cdots\dif x_{n}
\end{equation*}
si ha che
\begin{equation*}
\dpd{C}{a_{k}} = \sum_{i=1}^{n}a_{i}\,\rho_{ik} - m_{k}
\end{equation*}
ovvero, in forma matriciale, posta\footnote{Vedi:
\begin{itemize}
\item \href{../../../../../org/roam/20250104111539-spazio_delle_matrici.org}{Spazio delle matrici}
\item \href{../../../../../org/roam/20250113144338-matrice_trasposta.org}{Matrice Trasposta}
\item \href{../../../../../org/roam/20250624171244-gradiente_di_una_funzione.org}{Gradiente di una funzione}
\end{itemize}} \(\rho=(\rho_{ij})\), \(\bm{a} = \null^{T}(a_{1},\dots,a_{n})\) e \(\bm{m} = \null^{T}(m_{1},\dots,m_{n})\):
\begin{equation*}
\nabla C = \rho\, \bm{a} - \bm{m}
\end{equation*}

Dunque, posto che \(\rho\) sia \href{../../../../../org/roam/20250104111735-matrice_invertibile.org}{invertibile}, si ottiene che i valori ottimali per \(L\) siano
\begin{equation*}
\bm{a} = \rho^{-1}\bm{m}.
\end{equation*}

Nel caso di funzioni a valori in \(\R^{m}\) il problema si scompone nelle diverse coordinate.
\section{Funzioni di attivazione}
\label{sec:org4933a3a}
Nel Machine Learning le funzioni che agiscono nei \hyperref[sec:orge4cf044]{neuroni} vengono dette \uline{funzioni di attivazione}. Se ne presentano alcuni esempi, con i loro nomi specifici.

Sono tutte funzioni \(A \subseteq\R\to B \subseteq \R\).
\subsection{Funzioni Lineari}
\label{sec:org0e1a0fb}

Tra le funzioni di attivazione utilizzate vi sono le seguenti funzioni lineari:
\begin{itemize}
\item \(f(x) = kx\), per \(k > 0\) costante;
\item la funzione identità \(x\mapsto x\).
\end{itemize}
\subsection{Step Functions}
\label{sec:org496457b}

\subsubsection{Threshold step function}
\label{sec:orgcb4c9ac}

La \href{../../../../../org/roam/20250624161413-funzione_di_heaviside.org}{funzione di Heaviside} (vedi Fig. \ref{fig:heav})
\begin{equation*}
H(x)=\begin{cases}
1 & x\ge 0\\
0 & x<0
\end{cases}
\end{equation*}
la cui derivata (nel senso delle \href{../../../../../org/roam/20250625100117-distribuzione_analisi_matematica.org}{distribuzioni}) è una \href{../../../../../org/roam/20250625100133-delta_di_dirac.org}{Delta di Dirac}: \(H'(x) = \delta(x)\):
\begin{equation*}
\delta(x) = \begin{cases}
0 & x\neq 0\\
+\infty & x=0
\end{cases}
\end{equation*}
\begin{figure}
\begin{center}
\begin{tikzpicture}
\begin{axis}[axis lines=middle, axis equal]
\addplot[domain=-2:0, samples=100, ultra thick, red] {0};
\addplot[domain=0:2, samples=100, ultra thick, red] {1};
\end{axis}
\end{tikzpicture}
\end{center}
\caption{La funzione di Heaviside}\label{fig:heav}
\end{figure}
\subsubsection{Bipolar step function}
\label{sec:org8d72abe}

La funzione segno: (vedi Fig. \ref{fig:bip})
\begin{equation*}
S(x)= \begin{cases}
1 & x\ge{0}\\
-1 & x<0
\end{cases}
\end{equation*}
per cui vale: \(S(x)=2H(x)-1\). Pertanto la sua derivata è
\begin{equation*}
S'(x) = 2H'(x)=2\delta(x)
\end{equation*}
\begin{figure}
\begin{center}
\begin{tikzpicture}
\begin{axis}[axis lines=middle, axis equal]
\addplot[domain=-2:0, samples=100, ultra thick, red] {-1};
\addplot[domain=0:2, samples=100, ultra thick, red] {1};
\end{axis}
\end{tikzpicture}
\end{center}
\caption{La funzione segno}\label{fig:bip}
\end{figure}
\subsection{Hockeystick Functions}
\label{sec:orgcd88dae}

\subsubsection{ReLU}
\label{sec:orgc22b9be}

La \emph{Rectified Linear Unit} (ReLU) è (vedi Fig. \ref{fig:relu})
\begin{equation*}
\operatorname{ReLU}(x) = xH(x) = \max\set{0,x}
\end{equation*}
e la sua derivata \(\operatorname{ReLU}'(x) = H(x)\).

\begin{figure}
\begin{center}
\begin{tikzpicture}
\begin{axis}[axis lines=middle, axis equal]
\addplot[domain=-2:0, samples=100, ultra thick, red] {0};
\addplot[domain=0:2, samples=100, ultra thick, red] {x};
\end{axis}
\end{tikzpicture}
\end{center}
\caption{La funzione \(\operatorname{RELU}(x)\)}\label{fig:relu}
\end{figure}
\subsubsection{PReLU}
\label{sec:org264ed09}

La \emph{Parametric Rectivied Linear Unit} (PReLU) è (vedi Fig \ref{fig:prelu}), per \(\alpha>0\)
\begin{equation*}
\operatorname{PReLU}(\alpha;x) = \operatorname{PReLU}_{\alpha}(x) = \begin{cases}
\alpha x & x<0\\
x & x \ge 0
\end{cases}
\end{equation*}

\begin{figure}
\begin{center}
\begin{tikzpicture}
\begin{axis}[axis lines=middle, axis equal]
\addplot[domain=-2:0, samples=100, ultra thick, red] {x};
\addplot[domain=0:2, samples=100, ultra thick, red] {2 * x};
\end{axis}
\end{tikzpicture}
\end{center}
\caption{La funzione \(\operatorname{PRELU}_{2}(x)\)}\label{fig:prelu}
\end{figure}
\subsubsection{ELU}
\label{sec:org23de31e}

La \emph{Exponential Linear Units} (ELU) è (vedi Fig. \ref{fig:elu}):
\begin{equation*}
\operatorname{ELU}(\alpha,x) = \begin{cases}
x &x>0\\
\alpha(e^{x}-1) &x\le 0
\end{cases}
\end{equation*}

\begin{figure}
\begin{center}
\begin{tikzpicture}
\begin{axis}[axis lines=middle, axis equal]
\addplot[domain=-2:0, samples=100, ultra thick, red] {x};
\addplot[domain=0:2, samples=100, ultra thick, red] {2 * exp(x) - 2};
\end{axis}
\end{tikzpicture}
\end{center}
\caption{La funzione \(\operatorname{ELU}(\alpha,x)\)}\label{fig:elu}
\end{figure}
\subsubsection{SELU}
\label{sec:org59343a7}

La \emph{Scaled Exponential Linear Units} (SELU) è (vedi Fig. \ref{fig:selu})
\begin{equation*}
\operatorname{SELU}(\alpha,\lambda,x) = \lambda\operatorname{ELU}(\alpha,x) = \begin{cases}
\lambda\,x & x>0\\
\alpha\lambda(e^{x}-1) &x\le 0.
\end{cases}
\end{equation*}

\begin{figure}
\begin{center}
\begin{tikzpicture}
\begin{axis}[axis lines=middle, axis equal]
\addplot[domain=-2:0, samples=100, ultra thick, red] {0.4 * x};
\addplot[domain=0:2, samples=100, ultra thick, red] {0.8 * exp(x) - 0.8};
\end{axis}
\end{tikzpicture}
\end{center}
\caption{La funzione \(\operatorname{SELU}(0.4,2,x)\)}\label{fig:selu}
\end{figure}
\subsubsection{SLU}
\label{sec:orgec6050c}

La \emph{Sigmoid Linear Units} (SLU) è (vedi Fig. \ref{fig:slu})
\begin{equation*}
\phi(x) = \frac{x}{1+e^{-x}}.
\end{equation*}

Questa non è una \href{../../../../../org/roam/20250203132953-funzione_monotona.org}{funzione monotona}, ma ha un \href{../../../../../org/roam/20250627153543-massimo_e_minimo_di_una_funzione_reale.org}{minimo} in \(x_{0}\approx -1,27\).

Spesso si usa anche la versione parametrica:
\begin{equation*}
\phi_{c}(x) = \frac{x}{1+e^{-cx}}.
\end{equation*}

\begin{figure}
\begin{center}
\begin{tikzpicture}
\begin{axis}[axis lines=middle, axis equal]
\addplot[domain=-7:7, samples=100, ultra thick, red] {x / (1 + exp(-x))};
\end{axis}
\end{tikzpicture}
\end{center}
\caption{La funzione \(\operatorname{SLU}(x)\)}\label{fig:slu}
\end{figure}
\subsubsection{Softplus}
\label{sec:org821867c}

Questa è una funzione positiva crescente, con \href{../../../../../org/roam/20250202173528-dominio_range_e_campo_di_una_classe_relazione.org}{range} \((0,+\infty)\): (vedi Fig. \ref{fig:sp})
\begin{equation*}
\operatorname{sp}(x) = \ln(1+e^{x}).
\end{equation*}

\begin{figure}
\begin{center}
\begin{tikzpicture}
\begin{axis}[axis lines=middle, axis equal]
\addplot[domain=-3:3, samples=100, ultra thick, red] {ln(1 + exp(x))};
\end{axis}
\end{tikzpicture}
\end{center}
\caption{La funzione \(\operatorname{sp}(x)\)}\label{fig:sp}
\end{figure}

Inoltre
\begin{align*}
\operatorname{sp}(x)- \operatorname{sp}(-x) &= \ln(1+e^{x}) - \ln(1+e^{-x}) \\
&= \ln\left(\frac{1+e^{x}}{1+e^{-x}}\right) = \ln\left(\frac{1+e^{x}}{e^{-x}(1+e^{x})}\right) \\
&= \ln e^{x} = x.
\end{align*}
La sua derivata è
\begin{equation*}
\operatorname{sp}'(x) = \frac{1}{1+e^{-x}}>0.
\end{equation*}
\subsection{Funzioni Sigmoidali}
\label{sec:orgbb05a4b}

\subsubsection{Logistic Function}
\label{sec:orgf0e6195}

La funzione logistica è (vedi Fig. \ref{fig:logistic})
\begin{equation*}
\sigma_{c}(x) = \sigma(c;x) = \frac{1}{1+e^{-cx}}.
\end{equation*}

\begin{figure}
\begin{center}
\begin{tikzpicture}
\begin{axis}[axis lines=middle, axis equal]
\addplot[domain=-3:3, samples=100, ultra thick, red] {1 / (1 + exp(- 2 * x))};
\end{axis}
\end{tikzpicture}
\end{center}
\caption{La funzione \(\sigma_{2}(x)\)}\label{fig:logistic}
\end{figure}

La famiglia di funzioni \((\sigma_{c}(x))_{c \in (0,+\infty)}\) approssima la \href{../../../../../org/roam/20250624161413-funzione_di_heaviside.org}{funzione di Heaviside} \(H(x)\), in quanto
\begin{equation*}
\lim_{c\to \infty} e^{-cx} = \begin{cases}
0 & x>0\\
1 & x=0\\
+ \infty & x<0
\end{cases}
\end{equation*}
e pertanto
\begin{equation*}
\lim_{c\to+\infty} \sigma_{c}(x) = \begin{cases}
1 &x>0\\
\frac{1}{2} & x=0\\
0 &x<0
\end{cases}
\end{equation*}
e pertanto, per ogni \(x\neq 0\): \(H(x) =\lim_{c\to+\infty}\sigma_{c}(x)\).

Le funzioni logistiche sono soluzioni della seguente equazione differenziale:
\begin{equation*}
\sigma_{c}' = c\sigma_{c}\,(1-\sigma_{c})
\end{equation*}
infatti:
\begin{align*}
\sigma_{c}'(x) &= - \frac{1}{(1+e^{-cx})^{2}} \cdot (-c\,e^{-cx})\\
&= c \cdot \frac{1}{1+e^{-cx}} \cdot \frac{e^{-cx}}{1+e^{-cx}}\\
&= c \cdot \frac{1}{1+e^{-cx}} \cdot \left(\frac{e^{-cx}+1-1}{1+e^{-cx}}\right)\\
&= c \cdot \frac{1}{1+e^{-cx}} \cdot \left(1+\frac{-1}{1+e^{-cx}}\right)\\
&= c\cdot \sigma_{c}(x) \cdot (1-\sigma_{c}(x)).
\end{align*}
\subsubsection{Tangente Iperbolica}
\label{sec:org5d70533}

La \uline{\href{../../../../../org/roam/20250627184228-funzioni_iperboliche.org}{tangente iperbolica}} \(\tanh(x)\) è (vedi Fig. \ref{fig:tanh})
\begin{equation*}
\tanh(x) = \frac{e^{x}-e^{-x}}{e^{x}+e^{-x}} = 2\sigma_{2}(x)-1
\end{equation*}

\begin{figure}
\begin{center}
\begin{tikzpicture}
\begin{axis}[axis lines=middle, axis equal]
\addplot[domain=-2:2, samples=100, ultra thick, red] {(exp(x) - exp(-x)) / (exp(x) + exp(-x))};
\end{axis}
\end{tikzpicture}
\end{center}
\caption{La funzione \(\tanh(x)\)}\label{fig:tanh}
\end{figure}

Inoltre si ha che \(\tanh'(x) = 1-(\tanh(x))^{2}\):
\begin{align*}
\tanh'(x) &= 2\sigma_{2}'(x) = 2\cdot 2\sigma_{2}(x)\cdot(1-\sigma_{2}(x))\\
&= 2\sigma_{2}(x) \cdot (2-2\sigma_{2}(x))\\
&= (\tanh(x)+1) \cdot (1 - 2\sigma_{2}(x)+1)\\
&= (\tanh(x)+1)(-\tanh(x)+1) = 1-(\tanh(x))^{2}
\end{align*}
\subsubsection{Arcotangente}
\label{sec:org5036684}

È spesso utilizzata la seguente \href{../../../../../org/roam/20250627184319-funzioni_trigonometriche.org}{arcotangente} (vedi Fig. \ref{fig:arctan}):
\begin{equation*}
h(x) = \frac{2}{\pi} \arctan(x) \qquad x \in \R.
\end{equation*}

\begin{figure}
\begin{center}
\begin{tikzpicture}
\begin{axis}[axis lines=middle, axis equal]
\addplot[domain=-2:2, samples=100, ultra thick, red] {rad(atan(x)) * 2 / 3.1415};
\end{axis}
\end{tikzpicture}
\end{center}
\caption{La funzione \(h(x)\)}\label{fig:arctan}
\end{figure}
\subsubsection{Softsign}
\label{sec:orga284830}

La seguente funzione differenziabile è la funzione \emph{softsign}: (vedi Fig. \ref{fig:softsign})
\begin{equation*}
\operatorname{so}(x)=\frac{x}{1+|x|},\qquad x \in \R
\end{equation*}
che ha raange \((-1,1)\).

\begin{figure}
\begin{center}
\begin{tikzpicture}
\begin{axis}[axis lines=middle, axis equal]
\addplot[domain=-2:2, samples=100, ultra thick, red] {x / (1 + abs(x))};
\end{axis}
\end{tikzpicture}
\end{center}
\caption{La funzione \(\operatorname{so}(x)\)\)}\label{fig:softsign}
\end{figure}
\subsubsection{Piecewise Linear}
\label{sec:org9edb4be}

Dato un parametro \(\alpha>0\) (vedi Fig. \ref{fig:pieclin})
\begin{equation*}
f_{\alpha}(x) = f(\alpha,x) = \begin{cases}
-1 & x\le-\alpha\\
x/\alpha & -\alpha<x<\alpha\\
1 &x\ge \alpha.
\end{cases}
\end{equation*}

\begin{figure}
\begin{center}
\begin{tikzpicture}
\begin{axis}[axis lines=middle, axis equal]
\addplot[domain=-4:-2, samples=100, ultra thick, red] {-1};
\addplot[domain=-2:2, samples=100, ultra thick, red] {x / 2};
\addplot[domain=2:4, samples=100, ultra thick, red] {1};
\end{axis}
\end{tikzpicture}
\end{center}
\caption{La funzione \(f_{2}(x)\)}\label{fig:pieclin}
\end{figure}
\subsection{Bumped-type Functions}
\label{sec:org5113ec8}

\subsubsection{Gaussiana}
\label{sec:org6ea170f}

La funzione gaussiana mappa \(\R\) nell'intervallo \((0,1]\): (vedi Fig. \ref{fig:gauss})
\begin{equation*}
g(x) = e^{-x^{2}},\qquad x \in \R.
\end{equation*}

\begin{figure}
\begin{center}
\begin{tikzpicture}
\begin{axis}[axis lines=middle, axis equal]
\addplot[domain=-4:4, samples=100, ultra thick, red] {exp(- x * x)};
\end{axis}
\end{tikzpicture}
\end{center}
\caption{La funzione \(g(x)\)}\label{fig:gauss}
\end{figure}
\subsubsection{Doppio esponenziale}
\label{sec:orga6ff645}

Mappa la retta reale nell'intervallo \((0,1]\) ed è definita: (vedi Fig. \ref{fig:dexp})
\begin{equation*}
f(x) = e^{-\lambda\,|x|},\qquad x \in \R, \lambda>0.
\end{equation*}

\begin{figure}
\begin{center}
\begin{tikzpicture}
\begin{axis}[axis lines=middle, axis equal]
\addplot[domain=-4:0.01, samples=100, ultra thick, red] {exp(2 * x)};
\addplot[domain=-0.01:4, samples=100, ultra thick, red] {exp(- 2 * x)};
\end{axis}
\end{tikzpicture}
\end{center}
\caption{La funzione \(f(x)\) con parametro \(\lambda=2\)}\label{fig:dexp}
\end{figure}
\section{Rete Neurale}
\label{sec:org521d11a}
Una \uline{rete neurale} è [\ldots{}]

Questa riceve degli \uline{input} e produce un \uline{output}, in base a certi parametri \(\bm{w}\), per simulare la \uline{FUNZIONE TARGET}; quest'ultima è l'obiettivo finale della Rete Neurale (ovvero si vuole far sì che l'output della rete neurale sia il più vicino possibile al risultato della funzione target).

Per misurare la distanza tra l'output di una rete e la funzione target si utilizza una \uline{funzione errore} (o \uline{funzione costo}), che deve essere scelta in base all'applicazione specifica.

Il \uline{\hyperref[sec:org95c6761]{processo di apprendimento}} è quello che, partendo dai parametri \(\bm{w}\), li modifica (iterativamente), fino a dei parametri \(\bm{w}^{*}\), che sono \uline{ottimali}, nel senso che minimizzano la \uline{funzione errore}. Dunque il processo di apprendimento comporta la minimizzazione della funzione costo.
\section{Funzioni costo (Machine Learning)}
\label{sec:org5df5a3b}
Una funzione costo è una funzione che misura, dati certi parametri \(\bm{w}\) di una rete neurale, \uline{quanto la rete neurale si discosta dalla funzione target}.
\subsection{La Funzione Errore Supremum}
\label{sec:org2664c6c}

Una rete neurale prende input \(x \in [0,1]\) e deve imparare una data funzione continua \(\phi:[0,1]\to [0,1]\).

La funzione della rete neurale, dipendete dai parametri \(\bm{w},b\), è \(f_{\bm{w},b}(x)\).

La funzione costo Supremum è
\begin{equation*}
C(\bm{w},b) \coloneqq \sup_{x \in [0,1]}|f_{\bm{w},b}(x)-\phi(x)|.
\end{equation*}

Se la funzione \(\phi\) è conosciuta solo per \(N\) valori \(x_{1},\dots,x_{N}\), allora la funzione costo diventa
\begin{equation*}
C(\bm{w},b) \coloneqq \max_{i=1,\dots, N} |f_{\bm{w},b}(x_{i})-\phi(x_{i})|.
\end{equation*}
\subsection{La Funzione Errore Norma L2}
\label{sec:orged2a8ef}

Una rete neurale prende input \(x \in [0,1]\) e deve imparare una data funzione \(\phi:[0,1]\to \R\) tale che
\begin{equation*}
\int_{0}^{1}(\phi(x))^{2}\dif x <\infty
\end{equation*}

La funzione della rete neurale, dipendete dai parametri \(\bm{w},\bm{b}\), è \(f_{\bm{w},\bm{b}}(x)\). La funzione costo associata a questo tipo di problema è quella che misura la distanza nella \href{../../../../../org/roam/20250625123506-spazio_normato.org}{norma} \href{../../../../../org/roam/20250624162220-spazi_lp.org}{\(L^{2}\)}:
\begin{equation*}
C(\bm{w},\bm{b}) \coloneqq \int_{[0,1]} (f_{\bm{w},\bm{b}}(x)-\phi(x))^{2}\dif x.
\end{equation*}

Se la funzione \(\phi\) è conosciuta soltanto in \(N\) punti
\begin{equation*}
z_{1}=\phi(x_{1}),\quad z_{2}=\phi(x_{2}),\qquad, z_{N} = \phi(x_{N})
\end{equation*}
allora, posti \(\bm{z}=(z_{1},\dots,z_{N})\) e \(\bm{x} = (x_{1},\dots,x_{N})\), la funzione costo diventa la \href{../../../../../org/roam/20250301193511-spazio_metrico.org}{distanza} in \(\R^{N}\) tra \(\bm{z}\) e \(f_{\bm{w},\bm{b}}(\bm{x}) \coloneqq \left(f_{\bm{w},\bm{b}}(z_{1}),\dots,f_{\bm{w},\bm{b}}(z_{N})\right)\):
\begin{equation*}
C(\bm{w},\bm{b}) = \norma{\bm{z}-f_{\bm{w},\bm{b}}(\bm{x})}^{2} = \sum_{i=1}^{N} |z_{i}-f_{\bm{w},\bm{b}}(x_{i})|^{2}
\end{equation*}
\subsubsection{Interpretazione Geometrica}
\label{sec:orge878c5f}

Fissati \(\bm{x}\) e \(\bm{z}\), la mappa \((\bm{w},\bm{b})\mapsto f_{\bm{w},\bm{b}}(\bm{x})\) rappresenta una ipersuperficie in \(\R^{N}\):
\begin{equation*}
\Phi(\bm{w},\bm{b}) = \begin{pmatrix}
\Phi_{1}(\bm{w},\bm{b})\\
\vdots\\
\Phi_{N}(\bm{w},\bm{b})\\
\end{pmatrix} = \begin{pmatrix}
f_{\bm{w},\bm{b}}(x_{1})\\
\vdots\\
f_{\bm{w},\bm{b}}(x_{N})
\end{pmatrix}
\end{equation*}
e la funzione costo \(C(\bm{w},\bm{b})\) è la \href{../../../../../org/roam/20250301193511-spazio_metrico.org}{distanza} euclidea in \(\R^{N}\) di un punto sulla ipersuperficie dal punto \(\bm{z}\). Si suppongano appropriate ipotesi di differenziabilità della ipersuperficie.

Il costo è minimizzato in \((\bm{w}^{*},\bm{b}^{*})\) quando la distanza è minima, ovvero quando \(\Phi(\bm{w}^{*},\bm{b}^{*})\) è la proiezione ortogonale di \(\bm{z}\) sulla ipersuperficie: questo significa che il vettore \(\Phi(\bm{w}^{*},\bm{b}^{*})-\bm{z}\) è ortogonale al \href{../../../../../org/roam/20250114102823-spazio_tangente_ad_un_punto_di_una_varieta_differenziabile.org}{piano tangente} alla ipersuperficie in \(\Phi(\bm{w}^{*},\bm{b}^{*})\): quest'ultimo è generato dai vettori\footnote{Vedi: ``\href{../../../../../org/roam/20250114103236-derivata_parziale.org}{Derivata parziale}''}
\begin{equation*}
\restriction{\partial_{w_{k}} \Phi(\bm{w},\bm{b})}{(\bm{w}^{*},\bm{b}^{*})}; \qquad \restriction{\partial_{b_{j}} \Phi(\bm{w},\bm{b})}{(\bm{w}^{*},\bm{b}^{*})}
\end{equation*}

Richiedere l'ortogonalità, quindi, significa richiedere che i prodotti scalari:
\begin{align*}
\left(\restriction{\partial_{w_{k}} \Phi(\bm{w},\bm{b})}{(\bm{w}^{*},\bm{b}^{*})}\right)\cdot (\Phi(\bm{w}^{*},\bm{b}^{*})-\bm{z}) &= 0\\
\left(\restriction{\partial_{b_{j}} \Phi(\bm{w},\bm{b})}{(\bm{w}^{*},\bm{b}^{*})}\right) \cdot(\Phi(\bm{w}^{*},\bm{b}^{*})-\bm{z}) &= 0.
\end{align*}

Queste sono le \uline{equazioni normali}, che operativamente diventano
\begin{align*}
\sum_{i=1}^{N} (f_{\bm{w},\bm{b}}(x_{i})-z_{i})\cdot \restriction{\partial_{w_{k}} f_{\bm{w},\bm{b}} (x_{i})}{(\bm{w},\bm{b}) = (\bm{w}^{*},\bm{b}^{*})} &= 0\\
\sum_{i=1}^{N} (f_{\bm{w},\bm{b}}(x_{i})-z_{i})\cdot \restriction{\partial_{b_{j}} f_{\bm{w},\bm{b}} (x_{i})}{(\bm{w},\bm{b}) = (\bm{w}^{*},\bm{b}^{*})} &= 0
\end{align*}
\subsection{Regolarizzazione della Funzione Costo (Machine Learning)}
\label{sec:org3ba723a}
Per evitare il fenomeno dell'\href{../../../../../org/roam/20250627103519-overfitting.org}{overfitting}, è bene mantenere i parametri \uline{piccoli}. Pertanto, data una \hyperref[sec:org5df5a3b]{funzione costo} \(C(\bm{w})\), la si \uline{regolarizza}, utilizzando una funzione costo \(G(\bm{w})\), data da \(C(\bm{w})\) più un termine di regolarizzazione.

\begin{description}
\item[{Regolarizzazione \(L^{2}\).}] Si aggiunge alla funzione \(C(\bm{w})\) la \href{../../../../../org/roam/20250627104832-p_norma_in_rn.org}{2-norma} in \(\R^{n}\) dei parametri:
\begin{equation*}
  G(\bm{w}) \coloneqq C(\bm{w}) + \lambda\norma{\bm{w}}^{2}_{2},\qquad\text{dove }\norma{\bm{w}}^{2}_{2} = \sum_{i=1}^{n} (w_{i})^{2}.
\end{equation*}
Il valore \(\lambda>0\) è un \href{../../../../../org/roam/20250627104011-moltiplicatore_di_lagrange.org}{moltiplicatore di Lagrange}; questo parametro deve essere scelto in maniera da minimizzare l'\emph{overfitting}.
\item[{Regolarizzazione \(L^{1}\).}] Si aggiunge alla funzione \(C(\bm{w})\) la 1-norma in \(\R^{n}\) dei parametri:
\begin{equation*}
  G(\bm{w}) \coloneqq C(\bm{w}) + \lambda\norma{\bm{w}}^{2}_{2},\qquad\text{dove }\norma{\bm{w}}_{1} = \sum_{i=1}^{n} |w_{i}|.
\end{equation*}
Il valore \(\lambda>0\) è un \href{../../../../../org/roam/20250627104011-moltiplicatore_di_lagrange.org}{moltiplicatore di Lagrange}. Questo metodo, non differenziabile nell'origine, potrebbe dare dei problemi nella ricerca dei minimi tramite il gradiente.
\item[{Potential Regolation.}] Sia \(U:\R^{n}\to \R^{+}\) tale che:
\begin{enumerate}
\item \(U(x) = 0\) se e solo se \(x=0\);
\item \(U\) ha un minimo assoluto in \(x=0\).
\end{enumerate}

La funzione costo regolarizzata diventa:
\begin{equation*}
  G(\bm{w}) = C(\bm{w}) + \lambda\, U(\bm{w}),\qquad\lambda>0
\end{equation*}

Il potenziale deve essere scelto in maniera tale che l'errore, utilizzando \(G\), sia \uline{minore} che utilizzando \(C\).
\end{description}
\section{Processo di apprendimento di una rete neurale}
\label{sec:org95c6761}
L'apprendimento di una \hyperref[sec:org521d11a]{rete neurale} è il processo di ricerca dei parametri ottimali per approssimare la funzione target. Questo è un processo iterativo algoritmico, che genera una \href{../../../../../org/roam/20250206170922-sequenze_e_stringhe.org}{sequenza} \((w_{t})\) di parametri. Poiché si parla di numeri immensi di elementi in questa sequenza, spesso ci si riferisce a \(t\) come una sorta di variabile temporale continua.

Si vuole allenare un modello per replicare una funzione target di cui si conoscono \(N\) valori: \(\set{(x_{i},z_{i})}\), minimizzando la funzione costo \(C(\bm{w})\).

Questo insieme è diviso in \uline{tre parti}:
\begin{itemize}
\item \uline{training set \(\mathcal{T}\)} (c.a. 70\% dei dati);
\item \uline{test set \(\mathrm{T}\)} (c.a. 20\% dei dati);
\item \uline{validation set \(\mathcal{V}\)} (c.a. 10\% dei dati).
\end{itemize}

Si suppone che siano identicamente distribuiti, e che siano indipendenti. Si ottengono quindi tre errori:
\begin{itemize}
\item \uline{errore di training \(C_{\mathcal{T}}(\bm{w})\)}: è il valore della funzione costo utilizzando i valori della funzione target presi dal training set;
\item \uline{errore di test \(C_{\mathrm{T}}(\bm{w})\)}: è il valore della funzione costo utilizzando i valori della funzione target presi dal test set;
\item \uline{validation error \(C_{\mathcal{V}}(\bm{w})\)}: è il valore della funzione costo utilizzando i valori della funzione target presi dal validation set.
\end{itemize}
\subsection{Errori di Training e di Test}
\label{sec:org396fea6}
Con un qualche algoritmo si trova il valore \(\bm{w}^{*}\) che minimizza \(C_{\mathcal{T}}\). Successivamente, si calcola \(C_{\mathrm{T}}(\bm{w}^{*})\), e generalmente vale:
\begin{equation*}
	C_{\mathcal{T}}(\bm{w}^{*}) \le C_{\mathrm{T}}(\bm{w}^{*})
\end{equation*}
Ci sono tre possibili scenari, a questo punto:
\begin{itemize}
\item sia \(C_{\mathcal{T}}(\bm{w}^{*})\) che \(C_{\mathrm{T}}(\bm{w}^{*})\) sono piccoli: questo è lo scenario desiderato;
\item \(C_{\mathcal{T}}(\bm{w}^{*})\) è piccolo, ma \(C_{\mathrm{T}}(\bm{w}^{*})\) è grande: questo è un fenomeno di \uline{overfitting}; questo significa che la rete neurale sta ``memorizzando'' il training set, e non riesce a generalizzare bene; probabilmente bisogna rivedere l'architettura della rete neurale, probabilmente diminuendo i parametri;
\item sia \(C_{\mathcal{T}}(\bm{w}^{*})\) che \(C_{\mathrm{T}}(\bm{w}^{*})\) sono grandi: questo è un fenomeno di \uline{underfitting}; bisogna rivedere l'architettura della rete neurale, probabilmente aumentando i parametri.
\end{itemize}

Pertanto si utilizza il \uline{test set} per verificare che i valori dei parametri trovati sul training set siano sufficientemente generalizzabili.
\subsection{Iperparametri di un processo di apprendimento}
\label{sec:org1fc7bc8}
L'algoritmo di apprendimento dipende da un insieme di parametri \uline{diversi} da quelli della rete neurale. Questi sono detti \uline{iperparametri}.

Si utilizza la mimimizzazione del \uline{validation error} proprio per regolare gli iperparametri.
\subsection{Alcuni esempi di algoritmi di apprendimento}
\label{sec:org6cf0759}

\subsubsection{Regressione Lineare}
\label{sec:orgf65a927}
\chapter{Cenni di Analisi Matematica}
\label{sec:org35ebc84}

\section{Teoria della misura}
\label{sec:org2a58170}

\subsection{Funzioni sigmoidali e funzioni discriminatorie}
\label{sec:orgf739669}

\begin{definizione}
Una funzione \(\sigma:\R\to [0,1]\) si dice \uline{sigmoidale} se\footnote{Vedi ``\href{../../../../../org/roam/20250625110412-limite_analisi_matematica.org}{Limite (Analisi Matematica)}''}
\begin{equation*}
\lim_{x\to-\infty} \sigma(x) = -1,\qquad \lim_{x\to +\infty} \sigma(x)= +1.
\end{equation*}
\end{definizione}
\begin{definizione}
Sia \(\mathcal{M}\) la famiglia delle \href{../../../../../org/roam/20250625104200-misura_di_baire.org}{misure di Baire} per \(\R^{n}\) sul cubo \(I^{n} \coloneqq [0,1]^{n} \subseteq \R\), \href{../../../../../org/roam/20250625110016-misura_finita.org}{finite}, \href{../../../../../org/roam/20250625110024-misura_con_segno.org}{con segno} e \href{../../../../../org/roam/20250625110032-misura_regolare.org}{regolari}.

Una funzione \(f: \R\to \R\) si dice \uline{discriminatoria per \(\mathcal{M}\)} se per ogni \(\mu \in \mathcal{M}\):
\begin{equation*}
\left(\forall \bm{w} \in \R^{n},\, \forall \theta \in \R\quad \int_{I^{n}} f(\bm{w}\cdot\bm{x}) \dif \mu(\bm{x}) = 0\right)\implies \mu=0
\end{equation*}
\end{definizione}
\begin{prop}
Ogni funzione \href{../../../../../org/roam/20250625110110-funzione_sigmoidale.org}{sigmoidale} \(\sigma:\R\to [0,1]\) è \href{../../../../../org/roam/20250625105528-funzione_discriminatoria_per_una_misura_di_baire_sul_cubo_unitario.org}{discriminatoria per \(\mathcal{M}\)}, dove \(\mathcal{M}\) è l'insieme \href{../../../../../org/roam/20250625104200-misura_di_baire.org}{misure di Baire} per \(\R^{n}\) sul cubo \(I^{n} \coloneqq [0,1]^{n} \subseteq \R\), \href{../../../../../org/roam/20250625110016-misura_finita.org}{finite}, \href{../../../../../org/roam/20250625110024-misura_con_segno.org}{con segno} e \href{../../../../../org/roam/20250625110032-misura_regolare.org}{regolare}.

Ovvero, se \(\sigma:\R\to [0,1]\) è tale che
\begin{equation*}
\lim_{x\to-\infty}\sigma(t) =0;\qquad \lim_{x\to+\infty}\sigma(t)=1
\end{equation*}
allora, per ogni \(\mu \in \mathcal{M}\),
\begin{equation*}
\left(\forall \bm{w} \in \R^{n},\, \forall \theta \in \R\quad \int_{I^{n}} f(\bm{w}\cdot\bm{x}) \dif \mu(\bm{x}) = 0\right)\implies \mu=0
\end{equation*}
\end{prop}
\section{Minimizzazione}
\label{sec:org5ac1f88}

\begin{definizione}
\lipsum[1]
\end{definizione}
\begin{prop}
\lipsum[1]
\end{prop}
\begin{lem}
\lipsum[2]
\end{lem}

\begin{lem}
\lipsum[3]
\end{lem}

\begin{thm}
\lipsum[4]
\end{thm}
\part{Cordero}
\part{Sirovich}
\end{document}
