% Created 2025-06-27 Fri 13:15
% Intended LaTeX compiler: pdflatex
\documentclass[10pt]{book}
%% CREATO CON ORG - EMACS
\newcommand{\use}[2][]{\usepackage[#1]{#2}}
% PACCHETTI FONDAMENTLAI
\use[utf8]{inputenc}
\use[T1]{fontenc}
\use{graphicx}
\use{longtable}
\use{wrapfig}
\use{rotating}
\use[normalem]{ulem}
\use{amsmath}
\use{amsthm}
\use{amssymb}
\use{capt-of}
\use[italian]{babel}
\use[babel]{csquotes}
\use[style=numeric, hyperref]{biblatex}
\use{microtype}
\use{lmodern}
\use{subfig} % sottofigure
\use{multicol} % due colonne
\use{lipsum} % lorem ipsum
\use{color} % colori in latex
\use{parskip} % rimuove l'indentazione dei nuovi paragrafi %% Add parbox=false to all new tcolorbox
\use{centernot}
\use[outline]{contour}\contourlength{3pt}
\use{fancyhdr}
\use{layout}
\use[most]{tcolorbox} % Riquadri colorati
\use{ifthen} % IFTHEN
\use{geometry}

% pacchetti matematica
\use{yhmath}
\use{dsfont}
\use{mathrsfs}
\use{cancel} % semplificare
\use{polynom} %divisione tra polinomi
\use{forest} % grafi ad albero
\use{booktabs} % tabelle
\use{commath} %simboli e differenziali
\use{bm} %bold
\use[fulladjust]{marginnote} %to use marginnote for date notes
\use{arrayjobx}%array
\use[intlimits]{empheq} % Riquadri colorati attorno alle equazioni
\use{mathtools}
\use{circuitikz} % Disegnare i circuiti

%%%%%%%%%%%%%


%%%% QUIVER
\newcommand{\duepunti}{\,\mathchar\numexpr"6000+`:\relax\,}
% A TikZ style for curved arrows of a fixed height, due to AndréC.
\tikzset{curve/.style={settings={#1},to path={(\tikztostart)
    .. controls ($(\tikztostart)!\pv{pos}!(\tikztotarget)!\pv{height}!270:(\tikztotarget)$)
    and ($(\tikztostart)!1-\pv{pos}!(\tikztotarget)!\pv{height}!270:(\tikztotarget)$)
    .. (\tikztotarget)\tikztonodes}},
    settings/.code={\tikzset{quiver/.cd,#1}
        \def\pv##1{\pgfkeysvalueof{/tikz/quiver/##1}}},
    quiver/.cd,pos/.initial=0.35,height/.initial=0}

% TikZ arrowhead/tail styles.
\tikzset{tail reversed/.code={\pgfsetarrowsstart{tikzcd to}}}
\tikzset{2tail/.code={\pgfsetarrowsstart{Implies[reversed]}}}
\tikzset{2tail reversed/.code={\pgfsetarrowsstart{Implies}}}
% TikZ arrow styles.
\tikzset{no body/.style={/tikz/dash pattern=on 0 off 1mm}}
%%%%%%%%%%


%% DEFINIZIONI COMANDI MATEMATICI
\let\sin\relax %TOGLIE LA DEFINIZIONE SU "\sin"

% cambia la definizione di empty set
% ---
\let\oldemptyset\emptyset
% ---
% \let\emptyset\varnothing
% ---
% \let\emptyset\relax
% \newcommand{\emptyset}{\text{\textnormal{\O}}}
% ---

\DeclareMathOperator{\bounded}{bd}
\DeclareMathOperator{\sin}{sen}
\DeclareMathOperator{\epi}{Epi}
\DeclareMathOperator{\cl}{cl}
\DeclareMathOperator{\graph}{graph}
\DeclareMathOperator{\arcsec}{arcsec}
\DeclareMathOperator{\arccot}{arccot}
\DeclareMathOperator{\arccsc}{arccsc}
\DeclareMathOperator{\spettro}{Spettro}
\DeclareMathOperator{\nulls}{nullspace}
\DeclareMathOperator{\dom}{dom}
\DeclareMathOperator{\ar}{ar}
\DeclareMathOperator{\const}{Const}
\DeclareMathOperator{\fun}{Fun}
\DeclareMathOperator{\rel}{Rel}
\DeclareMathOperator{\altezza}{ht}
\let\det\relax %TOGLIE LA DEFINIZIONE SU "\det"
\DeclareMathOperator{\det}{det}
\DeclareMathOperator{\End}{End}
\DeclareMathOperator{\gl}{GL}
\DeclareMathOperator{\Id}{Id}
\DeclareMathOperator{\id}{Id}
\DeclareMathOperator{\I}{\mathds{1}}
\DeclareMathOperator{\II}{II}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\tc}{t.c.}
\DeclareMathOperator{\T}{T}
\DeclareMathOperator{\var}{Var}
\DeclareMathOperator{\cov}{Cov}
\DeclareMathOperator{\st}{st}
\DeclareMathOperator{\mon}{Mon}
\newcommand{\card}[1]{\left\vert #1 \right\vert}
\newcommand{\trasposta}[1]{\prescript{\text{T}}{}{#1}}
\newcommand{\1}{\mathds{1}}
\newcommand{\R}{\mathds{R}}
\newcommand{\diesis}{\#}
\newcommand{\bemolle}{\flat}
\newcommand{\nonstandard}[1]{\prescript{*}{}{#1}}
\newcommand{\starR}{\nonstandard{\R}}
\newcommand{\borel}{\mathscr{B}}
\newcommand{\lebesgue}[1]{\mathscr{L}\left(#1\right)}
\newcommand{\media}{\mathds{E}}
\newcommand{\K}{\mathds{K}}
\newcommand{\A}{\mathds{A}}
\newcommand{\Q}{\mathds{Q}}
\newcommand{\N}{\mathds{N}}
\newcommand{\C}{\mathds{C}}
\newcommand{\Z}{\mathds{Z}}
\newcommand{\qo}{\hspace{1em}\text{q.o.}\,}
\renewcommand{\tilde}[1]{\widetilde{#1}}
\renewcommand{\parallel}{\mathrel{/\mkern-5mu/}}
\newcommand{\parti}[2][]{\wp_{#1}(#2)}
\newcommand{\diff}[1]{\operatorname{d}_{#1}}
\let\oldvec\vec
\renewcommand{\vec}[1]{\overrightarrow{\vphantom{i}#1}}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\cat}[1]{\mathbf{#1}}
\newcommand{\dfreccia}[1]{\xrightarrow{\ #1 \ }}
\newcommand{\sfreccia}[1]{\xleftarrow{\ #1 \ }}
\newcommand{\formalsum}[2]{{\sum_{#1}^{#2}}{\vphantom{\sum}}'}
\newcommand{\minim}[2]{\mu_{#1}\, \left(#2\right)}
\newcommand{\concat}{\null^{\frown}} % concatenazione di stringe
\newcommand{\godelcode}[1]{\langle\!\langle #1 \rangle\!\rangle}
\newcommand{\godeldec}[1]{(\!(#1)\!)}
\newcommand{\termcode}[1]{\ulcorner #1\urcorner}
\newcommand{\partialto}{\dashrightarrow}
\newcommand{\restricted}{\upharpoonright}
\newcommand{\embeds}{\precsim}
\newcommand{\surjects}{\twoheadrightarrow}
\newcommand{\equipotenti}{\asymp}
%% \newcommand{\dotplus}{\mathbin{\dot{+}}} %% A quanto pare esiste già
\newcommand{\bigdot}{\mathbin{\boldsymbol{\cdot}}}
\newcommand{\dotexp}[1]{^{.#1}}

%% Definizione di \dotminus

\makeatletter
\newcommand{\dotminus}{\mathbin{\text{\@dotminus}}}

\newcommand{\@dotminus}{%
  \ooalign{\hidewidth\raise1ex\hbox{.}\hidewidth\cr$\m@th-$\cr}%
}
\makeatother

%tramite i prossimi due comandi posso decidere come scrivere i logaritmi naturali in tutti i documenti: ho infatti eliminato qualsiasi differenza tra "ln" e "log": se si vuole qualcosa di diverso bisogna inserire manualmente il tutto
\let\ln\relax
\DeclareMathOperator{\ln}{ln}
\let\log\relax
\DeclareMathOperator{\log}{log}
%%%%%%

%% NUOVI COMANDI
\newcommand{\straniero}[1]{\textit{#1}} %parole straniere
\newcommand{\titolo}[1]{\textsc{#1}} %titoli
\newcommand{\qedd}{\tag*{$\blacksquare$}} %qed per ambienti matemastici
\renewcommand{\qedsymbol}{$\blacksquare$} %modifica colore qed
\newcommand{\ooverline}[1]{\overline{\overline{#1}}}
\newcommand{\circoletto}[1]{\left(#1\right)^{\text{o}}}
%
\newcommand{\qmatrice}[1]{\begin{pmatrix}
#1_{11} & \cdots & #1_{1n}\\
\vdots & \ddots & \vdots \\
#1_{m1} & \cdots & #1_{mn}
\end{pmatrix}}
%
\newcommand{\parentesi}[2]{%
\underset{#1}{\underbrace{#2}}%
}
%
\newcommand{\norma}[1]{% Norma
\left\lVert#1\right\rVert%
}
\newcommand{\scalare}[2]{% Scalare
\left\langle #1, #2\right\rangle
}
%%%%%

%% RESTRIZIONI
\newcommand{\referenze}[2]{
	\phantomsection{}#2\textsuperscript{\textcolor{blue}{\textbf{#1}}}
}

\let\restriction\relax

\def\restriction#1#2{\mathchoice
              {\setbox1\hbox{${\displaystyle #1}_{\scriptstyle #2}$}
              \restrictionaux{#1}{#2}}
              {\setbox1\hbox{${\textstyle #1}_{\scriptstyle #2}$}
              \restrictionaux{#1}{#2}}
              {\setbox1\hbox{${\scriptstyle #1}_{\scriptscriptstyle #2}$}
              \restrictionaux{#1}{#2}}
              {\setbox1\hbox{${\scriptscriptstyle #1}_{\scriptscriptstyle #2}$}
              \restrictionaux{#1}{#2}}}
\def\restrictionaux#1#2{{#1\,\smash{\vrule height .8\ht1 depth .85\dp1}}_{\,#2}}
%%%%%%%%%%%

%% SEZIONE GRAFICA
\use{tikz}
\usetikzlibrary{matrix, patterns, calc, decorations.pathreplacing, hobby, decorations.markings, decorations.pathmorphing, babel}
\use{tikz-3dplot}
\use{mathrsfs} %per geogebra
\use{tikz-cd}
\tikzset
{
  %surface/.style={fill=black!10, shading=ball,fill opacity=0.4},
  plane/.style={black,pattern=north east lines},
  curve/.style={black,line width=0.5mm},
  dritto/.style={decoration={markings,mark=at position 0.5 with {\arrow{Stealth}}}, postaction=decorate},
  rovescio/.style={decoration={markings,mark=at position 0.5 with {\arrow{Stealth[reversed]}}}, postaction=decorate}
}
\use{pgfplots} % stampare le funzioni
	\pgfplotsset{/pgf/number format/use comma,compat=1.15}
	%\pgfplotsset{compat=1.15} %per geogebra
	\usepgfplotslibrary{fillbetween, polar}
%%%%%%

%% CITAZIONI
\use{lineno}

\newcommand{\citazione}[1]{%
  \begin{quotation}
  \begin{linenumbers}
  \modulolinenumbers[5]
  \begingroup
  \setlength{\parindent}{0cm}
  \noindent #1
  \endgroup
  \end{linenumbers}
  \end{quotation}\setcounter{linenumber}{1}
  }
%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% AMS THM

\theoremstyle{definition}% default
\newtheorem{thm}{Teorema}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposizione}
\newtheorem{cor}[thm]{Corollario}
\theoremstyle{plain}
\newtheorem{definizione}[thm]{Definizione}
\theoremstyle{remark}
\newtheorem*{oss}{Osservazione}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\use{hyperref}
\hypersetup{%
	pdfauthor={Davide Peccioli},
	pdfsubject={},
	allcolors=black,
	citecolor=black,
%	colorlinks=true,
	bookmarksopen=true}
\pagestyle{empty}

\renewcommand{\href}[2]{\textcolor{blue}{#2}}
\author{Davide Peccioli}
\date{a.a. 2024-25}
\title{Metodi Matematici per il Machine Learning}
\begin{document}

\maketitle
\tableofcontents

\part{De Rossi}
\chapter{Reti Neurali}
\label{sec:orgaa37787}

\section{Neurone Artificiale}
\label{sec:org7f4e753}
Un \uline{neurone} è una cellula del corpo umano che può essere schematizzata come segue:
\begin{quote}
A neuron is a cell which consists of the following parts: dendrites, axon,and body-cell. The synapse is the connection between the axon of one neuron and the dendrite of another. The functions of each part is briefly described below:
\begin{itemize}
\item Dendrites are transmission channels that collect information from the axons of other neurons. The signal traveling through an axon reaches its terminal end and produces some chemicals \(x_{i}\) which are liberated in the synaptic gap. These chemicals are acting on the dendrites of the next neuron either in a strong or a weak way. The connection strength is described by the weight system \(w_{i}\)-
\item The body-cell collects all signals from dendrites. Here the dendrites activity adds up into a total potential and if a certain threshold is reached, the neuron fires a signal through the axon. The threshold depends on the sensitivity of the neuron and measures how easy is to get the neuron to fire.
\item The axon is the channel for signal propagation. The signal consists in the movement of ions from the body-cell towards the end of the axon. The signal is transmitted electrochemically to the dendrites of the next neuron.
\end{itemize}
\end{quote}

Matematicamente, quindi, si considera un neurone come una unità che riceve degli input (un vettore \(\bm{x}\)), lo \href{../../../../../org/roam/20250625095723-prodotto_scalare.org}{moltiplica} per un vettore di pesi \(\bm{w} = (w_{0},\dots,w_{n})\), e produce un output processando il prodotto scalare tramite una \uline{\href{../../../../../org/roam/20250624155858-neurone_artificiale.org}{funzione di attivazione}}:
\begin{equation*}
\begin{tikzcd}[ampersand replacement=\&,cramped]
	{\text{Input: }\bm{x}} \\
	{\bm{x}\cdot\bm{w}} \\
	{\text{Funzione di attivazione}} \\
	{\text{Output: }y}
	\arrow[from=1-1, to=2-1]
	\arrow[from=2-1, to=3-1]
	\arrow[from=3-1, to=4-1]
\end{tikzcd}
\end{equation*}
\subsection{Neurone Sigma-Heaviside}
\label{sec:org89ae928}

Il modello più semplice è quello che riceve degli input, li somma dopo averli moltiplicati per dei pesi, e:
\begin{itemize}
\item restituisce \(0\) se la somma così ottenuta non supera un \uline{treshold} \(b\);
\item restituisce \(1\) se la somma così ottenuta è maggiore o uguale a \(b\).
\end{itemize}

Questo viene schematizzato in questo modo:
\begin{equation*}
\begin{tikzcd}[ampersand replacement=\&,cramped]
	{-1} \\
	{x_1} \\
	{x_2} \&\& {\boxed{\Sigma, H}} \&\& y \\
	\vdots \\
	{x_n}
	\arrow["b"{description}, from=1-1, to=3-3]
	\arrow["{w_1}"{description}, from=2-1, to=3-3]
	\arrow["{w_2}"{description}, from=3-1, to=3-3]
	\arrow[from=3-3, to=3-5]
	\arrow["{w_n}"{description}, from=5-1, to=3-3]
\end{tikzcd}
\end{equation*}
e l'output \(y\) è dato da\footnote{La funzione \(H:\R\to \R\) è la \href{../../../../../org/roam/20250624161413-funzione_di_heaviside.org}{Funzione di Heaviside}:
\begin{equation*}
H(x) = \begin{cases}
1 & x\ge 0\\
0 & x<0
\end{cases}
\end{equation*}}
\begin{equation*}
y=H\left(\sum_{i=0}^{n} x_{i}\,w_{i}\right)
\end{equation*}
dove per convenzione si è posto \(w_{0}=b\) e \(x_{0}=-1\).

La convenzione è per semplicità di notazione, infatti
\begin{equation*}
H\left(\sum_{i=0}^{n} x_{i}\,w_{i}\right)=\begin{cases}
1 & \sum_{i=1}^{n} x_{i}\, w_{i}\ge b\\
0 & \sum_{i=1}^{n} x_{i}\, w_{i}< b
\end{cases}
\end{equation*}
\subsection{Regressione Lineare}
\label{sec:orgd504a7a}

Un altro esempio di neurone è quello che approssima\footnote{Approssima in senso \(L^{2}\) (ovvero minimizza la \href{../../../../../org/roam/20250624162220-spazi_lp.org}{norma \(L^{2}\)} della differenza).} una \href{../../../../../org/roam/20250103103252-funzione_continua.org}{funzione continua}
\begin{equation*}
f: K\to \R
\end{equation*}
con \(K \subseteq \R^{n}\) \href{../../../../../org/roam/20250103163701-spazio_topologico_compatto.org}{compatto}.

L'input del neurone sarà una \href{../../../../../org/roam/20250206170922-sequenze_e_stringhe.org}{\(n\)-upla} \(X=(x_{1},\dots,x_{n}) \in K\), mentre l'output sarà la funzione lineare
\begin{equation*}
L(X) = b+\sum_{i=1}^{n} a_{i}\,x_{i}
\end{equation*}

Per semplicità si considera l'approssimazione vicino allo zero, e si suppone che
\begin{equation*}
L(0)=f(0)=0
\end{equation*}
(a meno di traslazione verticale per \(f(0)\)).

Si vuole quindi minimizzare
\begin{equation*}
C(a_{1},\dots,a_{n}) = \frac{1}{2}\norma{f-L}_{L^{2}} = \frac{1}{2}\int_{K} \left(\sum_{i=1}^{n} a_{i}x_{i} - f(X)\right)^{2}\dif x_{1}\cdots\dif x_{n}
\end{equation*}
calcolandone il \href{../../../../../org/roam/20250624171244-gradiente_di_una_funzione.org}{gradiente}
\begin{align*}
\dpd{C}{a_{k}} &= \int_{K} x_{k} \left(\sum_{i=1}^{n} a_{i}x_{i} - f(X)\right)\dif x_{1}\cdots\dif x_{n}\\
&= \sum_{i=1}^{n} a_{i} \int_{K} x_{i} x_{k}\dif x_{1}\cdots\dif x_{n} - \int_{K} x_{k} f(X)\dif x_{1}\cdots\dif x_{n}
\end{align*}
e dunque, posti
\begin{equation*}
\rho_{ij} \coloneqq \int_{K} x_{i}x_{j}\dif x_{1}\cdots\dif x_{n},\qquad m_{k} \coloneqq \int_{K} x_{k}f(X)\dif x_{1}\cdots\dif x_{n}
\end{equation*}
si ha che
\begin{equation*}
\dpd{C}{a_{k}} = \sum_{i=1}^{n}a_{i}\,\rho_{ik} - m_{k}
\end{equation*}
ovvero, in forma matriciale, posta\footnote{Vedi:
\begin{itemize}
\item \href{../../../../../org/roam/20250104111539-spazio_delle_matrici.org}{Spazio delle matrici}
\item \href{../../../../../org/roam/20250113144338-matrice_trasposta.org}{Matrice Trasposta}
\item \href{../../../../../org/roam/20250624171244-gradiente_di_una_funzione.org}{Gradiente di una funzione}
\end{itemize}} \(\rho=(\rho_{ij})\), \(\bm{a} = \null^{T}(a_{1},\dots,a_{n})\) e \(\bm{m} = \null^{T}(m_{1},\dots,m_{n})\):
\begin{equation*}
\nabla C = \rho\, \bm{a} - \bm{m}
\end{equation*}

Dunque, posto che \(\rho\) sia \href{../../../../../org/roam/20250104111735-matrice_invertibile.org}{invertibile}, si ottiene che i valori ottimali per \(L\) siano
\begin{equation*}
\bm{a} = \rho^{-1}\bm{m}.
\end{equation*}

Nel caso di funzioni a valori in \(\R^{m}\) il problema si scompone nelle diverse coordinate.
\section{Rete Neurale}
\label{sec:org056a6da}
Una \uline{rete neurale} è [\ldots{}]

Questa riceve degli \uline{input} e produce un \uline{output}, in base a certi parametri \(\bm{w}\), per simulare la \uline{FUNZIONE TARGET}; quest'ultima è l'obiettivo finale della Rete Neurale (ovvero si vuole far sì che l'output della rete neurale sia il più vicino possibile al risultato della funzione target).

Per misurare la distanza tra l'output di una rete e la funzione target si utilizza una \uline{funzione errore} (o \uline{funzione costo}), che deve essere scelta in base all'applicazione specifica.

Il \uline{\hyperref[sec:org933f778]{processo di apprendimento}} è quello che, partendo dai parametri \(\bm{w}\), li modifica (iterativamente), fino a dei parametri \(\bm{w}^{*}\), che sono \uline{ottimali}, nel senso che minimizzano la \uline{funzione errore}. Dunque il processo di apprendimento comporta la minimizzazione della funzione costo.
\section{Funzioni costo (Machine Learning)}
\label{sec:orgf94918a}
Una funzione costo è una funzione che misura, dati certi parametri \(\bm{w}\) di una rete neurale, \uline{quanto la rete neurale si discosta dalla funzione target}.
\subsection{La Funzione Errore Supremum}
\label{sec:orgfa04425}

Una rete neurale prende input \(x \in [0,1]\) e deve imparare una data funzione continua \(\phi:[0,1]\to [0,1]\).

La funzione della rete neurale, dipendete dai parametri \(\bm{w},b\), è \(f_{\bm{w},b}(x)\).

La funzione costo Supremum è
\begin{equation*}
C(\bm{w},b) \coloneqq \sup_{x \in [0,1]}|f_{\bm{w},b}(x)-\phi(x)|.
\end{equation*}

Se la funzione \(\phi\) è conosciuta solo per \(N\) valori \(x_{1},\dots,x_{N}\), allora la funzione costo diventa
\begin{equation*}
C(\bm{w},b) \coloneqq \max_{i=1,\dots, N} |f_{\bm{w},b}(x_{i})-\phi(x_{i})|.
\end{equation*}
\subsection{La Funzione Errore Norma L2}
\label{sec:orgfcb8e21}

Una rete neurale prende input \(x \in [0,1]\) e deve imparare una data funzione \(\phi:[0,1]\to \R\) tale che
\begin{equation*}
\int_{0}^{1}(\phi(x))^{2}\dif x <\infty
\end{equation*}

La funzione della rete neurale, dipendete dai parametri \(\bm{w},\bm{b}\), è \(f_{\bm{w},\bm{b}}(x)\). La funzione costo associata a questo tipo di problema è quella che misura la distanza nella \href{../../../../../org/roam/20250625123506-spazio_normato.org}{norma} \href{../../../../../org/roam/20250624162220-spazi_lp.org}{\(L^{2}\)}:
\begin{equation*}
C(\bm{w},\bm{b}) \coloneqq \int_{[0,1]} (f_{\bm{w},\bm{b}}(x)-\phi(x))^{2}\dif x.
\end{equation*}

Se la funzione \(\phi\) è conosciuta soltanto in \(N\) punti
\begin{equation*}
z_{1}=\phi(x_{1}),\quad z_{2}=\phi(x_{2}),\qquad, z_{N} = \phi(x_{N})
\end{equation*}
allora, posti \(\bm{z}=(z_{1},\dots,z_{N})\) e \(\bm{x} = (x_{1},\dots,x_{N})\), la funzione costo diventa la \href{../../../../../org/roam/20250301193511-spazio_metrico.org}{distanza} in \(\R^{N}\) tra \(\bm{z}\) e \(f_{\bm{w},\bm{b}}(\bm{x}) \coloneqq \left(f_{\bm{w},\bm{b}}(z_{1}),\dots,f_{\bm{w},\bm{b}}(z_{N})\right)\):
\begin{equation*}
C(\bm{w},\bm{b}) = \norma{\bm{z}-f_{\bm{w},\bm{b}}(\bm{x})}^{2} = \sum_{i=1}^{N} |z_{i}-f_{\bm{w},\bm{b}}(x_{i})|^{2}
\end{equation*}
\subsubsection{Interpretazione Geometrica}
\label{sec:org75f4bbb}

Fissati \(\bm{x}\) e \(\bm{z}\), la mappa \((\bm{w},\bm{b})\mapsto f_{\bm{w},\bm{b}}(\bm{x})\) rappresenta una ipersuperficie in \(\R^{N}\):
\begin{equation*}
\Phi(\bm{w},\bm{b}) = \begin{pmatrix}
\Phi_{1}(\bm{w},\bm{b})\\
\vdots\\
\Phi_{N}(\bm{w},\bm{b})\\
\end{pmatrix} = \begin{pmatrix}
f_{\bm{w},\bm{b}}(x_{1})\\
\vdots\\
f_{\bm{w},\bm{b}}(x_{N})
\end{pmatrix}
\end{equation*}
e la funzione costo \(C(\bm{w},\bm{b})\) è la \href{../../../../../org/roam/20250301193511-spazio_metrico.org}{distanza} euclidea in \(\R^{N}\) di un punto sulla ipersuperficie dal punto \(\bm{z}\). Si suppongano appropriate ipotesi di differenziabilità della ipersuperficie.

Il costo è minimizzato in \((\bm{w}^{*},\bm{b}^{*})\) quando la distanza è minima, ovvero quando \(\Phi(\bm{w}^{*},\bm{b}^{*})\) è la proiezione ortogonale di \(\bm{z}\) sulla ipersuperficie: questo significa che il vettore \(\Phi(\bm{w}^{*},\bm{b}^{*})-\bm{z}\) è ortogonale al \href{../../../../../org/roam/20250114102823-spazio_tangente_ad_un_punto_di_una_varieta_differenziabile.org}{piano tangente} alla ipersuperficie in \(\Phi(\bm{w}^{*},\bm{b}^{*})\): quest'ultimo è generato dai vettori\footnote{Vedi: ``\href{../../../../../org/roam/20250114103236-derivata_parziale.org}{Derivata parziale}''}
\begin{equation*}
\restriction{\partial_{w_{k}} \Phi(\bm{w},\bm{b})}{(\bm{w}^{*},\bm{b}^{*})}; \qquad \restriction{\partial_{b_{j}} \Phi(\bm{w},\bm{b})}{(\bm{w}^{*},\bm{b}^{*})}
\end{equation*}

Richiedere l'ortogonalità, quindi, significa richiedere che i prodotti scalari:
\begin{align*}
\left(\restriction{\partial_{w_{k}} \Phi(\bm{w},\bm{b})}{(\bm{w}^{*},\bm{b}^{*})}\right)\cdot (\Phi(\bm{w}^{*},\bm{b}^{*})-\bm{z}) &= 0\\
\left(\restriction{\partial_{b_{j}} \Phi(\bm{w},\bm{b})}{(\bm{w}^{*},\bm{b}^{*})}\right) \cdot(\Phi(\bm{w}^{*},\bm{b}^{*})-\bm{z}) &= 0.
\end{align*}

Queste sono le \uline{equazioni normali}, che operativamente diventano
\begin{align*}
\sum_{i=1}^{N} (f_{\bm{w},\bm{b}}(x_{i})-z_{i})\cdot \restriction{\partial_{w_{k}} f_{\bm{w},\bm{b}} (x_{i})}{(\bm{w},\bm{b}) = (\bm{w}^{*},\bm{b}^{*})} &= 0\\
\sum_{i=1}^{N} (f_{\bm{w},\bm{b}}(x_{i})-z_{i})\cdot \restriction{\partial_{b_{j}} f_{\bm{w},\bm{b}} (x_{i})}{(\bm{w},\bm{b}) = (\bm{w}^{*},\bm{b}^{*})} &= 0
\end{align*}
\subsection{Regolarizzazione della Funzione Costo (Machine Learning)}
\label{sec:org62dbd3a}
Per evitare il fenomeno dell'\href{../../../../../org/roam/20250627103519-overfitting.org}{overfitting}, è bene mantenere i parametri \uline{piccoli}. Pertanto, data una \hyperref[sec:orgf94918a]{funzione costo} \(C(\bm{w})\), la si \uline{regolarizza}, utilizzando una funzione costo \(G(\bm{w})\), data da \(C(\bm{w})\) più un termine di regolarizzazione.

\begin{description}
\item[{Regolarizzazione \(L^{2}\).}] Si aggiunge alla funzione \(C(\bm{w})\) la \href{../../../../../org/roam/20250627104832-p_norma_in_rn.org}{2-norma} in \(\R^{n}\) dei parametri:
\begin{equation*}
  G(\bm{w}) \coloneqq C(\bm{w}) + \lambda\norma{\bm{w}}^{2}_{2},\qquad\text{dove }\norma{\bm{w}}^{2}_{2} = \sum_{i=1}^{n} (w_{i})^{2}.
\end{equation*}
Il valore \(\lambda>0\) è un \href{../../../../../org/roam/20250627104011-moltiplicatore_di_lagrange.org}{moltiplicatore di Lagrange}; questo parametro deve essere scelto in maniera da minimizzare l'\emph{overfitting}.
\item[{Regolarizzazione \(L^{1}\).}] Si aggiunge alla funzione \(C(\bm{w})\) la 1-norma in \(\R^{n}\) dei parametri:
\begin{equation*}
  G(\bm{w}) \coloneqq C(\bm{w}) + \lambda\norma{\bm{w}}^{2}_{2},\qquad\text{dove }\norma{\bm{w}}_{1} = \sum_{i=1}^{n} |w_{i}|.
\end{equation*}
Il valore \(\lambda>0\) è un \href{../../../../../org/roam/20250627104011-moltiplicatore_di_lagrange.org}{moltiplicatore di Lagrange}. Questo metodo, non differenziabile nell'origine, potrebbe dare dei problemi nella ricerca dei minimi tramite il gradiente.
\item[{Potential Regolation.}] Sia \(U:\R^{n}\to \R^{+}\) tale che:
\begin{enumerate}
\item \(U(x) = 0\) se e solo se \(x=0\);
\item \(U\) ha un minimo assoluto in \(x=0\).
\end{enumerate}

La funzione costo regolarizzata diventa:
\begin{equation*}
  G(\bm{w}) = C(\bm{w}) + \lambda\, U(\bm{w}),\qquad\lambda>0
\end{equation*}

Il potenziale deve essere scelto in maniera tale che l'errore, utilizzando \(G\), sia \uline{minore} che utilizzando \(C\).
\end{description}
\section{Processo di apprendimento di una rete neurale}
\label{sec:org933f778}
L'apprendimento di una \hyperref[sec:org056a6da]{rete neurale} è il processo di ricerca dei parametri ottimali per approssimare la funzione target. Questo è un processo iterativo algoritmico, che genera una \href{../../../../../org/roam/20250206170922-sequenze_e_stringhe.org}{sequenza} \((w_{t})\) di parametri. Poiché si parla di numeri immensi di elementi in questa sequenza, spesso ci si riferisce a \(t\) come una sorta di variabile temporale continua.

Si vuole allenare un modello per replicare una funzione target di cui si conoscono \(N\) valori: \(\set{(x_{i},z_{i})}\), minimizzando la funzione costo \(C(\bm{w})\).

Questo insieme è diviso in \uline{tre parti}:
\begin{itemize}
\item \uline{training set \(\mathcal{T}\)} (c.a. 70\% dei dati);
\item \uline{test set \(\mathrm{T}\)} (c.a. 20\% dei dati);
\item \uline{validation set \(\mathcal{V}\)} (c.a. 10\% dei dati).
\end{itemize}

Si suppone che siano identicamente distribuiti, e che siano indipendenti. Si ottengono quindi tre errori:
\begin{itemize}
\item \uline{errore di training \(C_{\mathcal{T}}(\bm{w})\)}: è il valore della funzione costo utilizzando i valori della funzione target presi dal training set;
\item \uline{errore di test \(C_{\mathrm{T}}(\bm{w})\)}: è il valore della funzione costo utilizzando i valori della funzione target presi dal test set;
\item \uline{validation error \(C_{\mathcal{V}}(\bm{w})\)}: è il valore della funzione costo utilizzando i valori della funzione target presi dal validation set.
\end{itemize}
\subsection{Errori di Training e di Test}
\label{sec:org6ec9b2d}
Con un qualche algoritmo si trova il valore \(\bm{w}^{*}\) che minimizza \(C_{\mathcal{T}}\). Successivamente, si calcola \(C_{\mathrm{T}}(\bm{w}^{*})\), e generalmente vale:
\begin{equation*}
	C_{\mathcal{T}}(\bm{w}^{*}) \le C_{\mathrm{T}}(\bm{w}^{*})
\end{equation*}
Ci sono tre possibili scenari, a questo punto:
\begin{itemize}
\item sia \(C_{\mathcal{T}}(\bm{w}^{*})\) che \(C_{\mathrm{T}}(\bm{w}^{*})\) sono piccoli: questo è lo scenario desiderato;
\item \(C_{\mathcal{T}}(\bm{w}^{*})\) è piccolo, ma \(C_{\mathrm{T}}(\bm{w}^{*})\) è grande: questo è un fenomeno di \uline{overfitting}; questo significa che la rete neurale sta ``memorizzando'' il training set, e non riesce a generalizzare bene; probabilmente bisogna rivedere l'architettura della rete neurale, probabilmente diminuendo i parametri;
\item sia \(C_{\mathcal{T}}(\bm{w}^{*})\) che \(C_{\mathrm{T}}(\bm{w}^{*})\) sono grandi: questo è un fenomeno di \uline{underfitting}; bisogna rivedere l'architettura della rete neurale, probabilmente aumentando i parametri.
\end{itemize}

Pertanto si utilizza il \uline{test set} per verificare che i valori dei parametri trovati sul training set siano sufficientemente generalizzabili.
\subsection{Iperparametri di un processo di apprendimento}
\label{sec:orgbc83b07}
L'algoritmo di apprendimento dipende da un insieme di parametri \uline{diversi} da quelli della rete neurale. Questi sono detti \uline{iperparametri}.

Si utilizza la mimimizzazione del \uline{validation error} proprio per regolare gli iperparametri.
\subsection{Alcuni esempi di algoritmi di apprendimento}
\label{sec:org5ccdf8b}

\subsubsection{Regressione Lineare}
\label{sec:org71041be}
\chapter{Cenni di Analisi Matematica}
\label{sec:org3476f14}

\section{Teoria della misura}
\label{sec:orgb88a416}

\subsection{Funzioni sigmoidali e funzioni discriminatorie}
\label{sec:org2e8370f}

\begin{definizione}
Una funzione \(\sigma:\R\to [0,1]\) si dice \uline{sigmoidale} se\footnote{Vedi ``\href{../../../../../org/roam/20250625110412-limite_analisi_matematica.org}{Limite (Analisi Matematica)}''}
\begin{equation*}
\lim_{x\to-\infty} \sigma(x) = -1,\qquad \lim_{x\to +\infty} \sigma(x)= +1.
\end{equation*}
\end{definizione}
\begin{definizione}
Sia \(\mathcal{M}\) la famiglia delle \href{../../../../../org/roam/20250625104200-misura_di_baire.org}{misure di Baire} per \(\R^{n}\) sul cubo \(I^{n} \coloneqq [0,1]^{n} \subseteq \R\), \href{../../../../../org/roam/20250625110016-misura_finita.org}{finite}, \href{../../../../../org/roam/20250625110024-misura_con_segno.org}{con segno} e \href{../../../../../org/roam/20250625110032-misura_regolare.org}{regolari}.

Una funzione \(f: \R\to \R\) si dice \uline{discriminatoria per \(\mathcal{M}\)} se per ogni \(\mu \in \mathcal{M}\):
\begin{equation*}
\left(\forall \bm{w} \in \R^{n},\, \forall \theta \in \R\quad \int_{I^{n}} f(\bm{w}\cdot\bm{x}) \dif \mu(\bm{x}) = 0\right)\implies \mu=0
\end{equation*}
\end{definizione}
\begin{prop}
Ogni funzione \href{../../../../../org/roam/20250625110110-funzione_sigmoidale.org}{sigmoidale} \(\sigma:\R\to [0,1]\) è \href{../../../../../org/roam/20250625105528-funzione_discriminatoria_per_una_misura_di_baire_sul_cubo_unitario.org}{discriminatoria per \(\mathcal{M}\)}, dove \(\mathcal{M}\) è l'insieme \href{../../../../../org/roam/20250625104200-misura_di_baire.org}{misure di Baire} per \(\R^{n}\) sul cubo \(I^{n} \coloneqq [0,1]^{n} \subseteq \R\), \href{../../../../../org/roam/20250625110016-misura_finita.org}{finite}, \href{../../../../../org/roam/20250625110024-misura_con_segno.org}{con segno} e \href{../../../../../org/roam/20250625110032-misura_regolare.org}{regolare}.

Ovvero, se \(\sigma:\R\to [0,1]\) è tale che
\begin{equation*}
\lim_{x\to-\infty}\sigma(t) =0;\qquad \lim_{x\to+\infty}\sigma(t)=1
\end{equation*}
allora, per ogni \(\mu \in \mathcal{M}\),
\begin{equation*}
\left(\forall \bm{w} \in \R^{n},\, \forall \theta \in \R\quad \int_{I^{n}} f(\bm{w}\cdot\bm{x}) \dif \mu(\bm{x}) = 0\right)\implies \mu=0
\end{equation*}
\end{prop}
\section{Minimizzazione}
\label{sec:orgcafe860}

\begin{definizione}

\end{definizione}
\begin{prop}
\lipsum[1]
\end{prop}
\begin{lem}
\lipsum[2]
\end{lem}

\begin{lem}
\lipsum[3]
\end{lem}

\begin{thm}
\lipsum[4]
\end{thm}
\part{Cordero}
\part{Sirovich}
\end{document}
